{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3a0d83-a9f7-4912-a8a1-1da5693795a9",
   "metadata": {},
   "source": [
    "# NN6: Zjawisko przeuczenia + regularyzacja (L2)\n",
    "Adrianna Grudzień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf4f18e-4599-4ca6-8261-be627f3b92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from py_files.activation_functions import Sigmoid, Linear, Softmax, Tanh, ReLU\n",
    "from py_files.metrics import mse, f_score, cross_entropy\n",
    "from py_files.prepare_data import read_classification_data, read_regression_data\n",
    "from py_files.network import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec79459-7590-40fe-a1fb-9b8a3f104e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_network(seeds=[123, 1, 2, 23, 42], build_args=None, fit_args=None):\n",
    "    scores_test = []\n",
    "    scores_train = []\n",
    "    nns  = []\n",
    "    for s in seeds:\n",
    "        nn = NN(**build_args, seed=s)\n",
    "        last_fa = None\n",
    "        for fa in fit_args:\n",
    "            nn.fit(**fa)\n",
    "            last_fa = fa\n",
    "        nns.append(nn)\n",
    "        scores_test.append(last_fa['metric'](last_fa['y_test'], nn.predict(last_fa['x_test'])))\n",
    "        scores_train.append(last_fa['metric'](last_fa['y_train'], nn.predict(last_fa['x_train'])))\n",
    "\n",
    "    return scores_train, scores_test, nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8a0f1f-376c-48dc-88ad-78dc87e15469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['metric', 'mean metric train', 'mean metric test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae551c9-cd11-40ef-a9c6-8bff887b8b43",
   "metadata": {},
   "source": [
    "# Zbiór `multimodal-sparse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db858a37-6003-407d-93fe-672690c4c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_x_train, ms_y_train = read_regression_data('../data/regression/multimodal-sparse-training.csv', index_col=None)\n",
    "ms_x_test, ms_y_test = read_regression_data('../data/regression/multimodal-sparse-test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e8707-84db-4e51-937b-08c08e5d2787",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Brak regularyzacji\n",
    "regularization_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b7ceb5-0047-4516-a689-3e4f1232e0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/700\n",
      "Loss on training set: 350.5856932506304, loss on test set: 729.8738387687808\n",
      "Epoch number 400/700\n",
      "Loss on training set: 17.25277971590778, loss on test set: 165.21724835335326\n",
      "Epoch number 400/700\n",
      "Loss on training set: 9.511991995327717, loss on test set: 114.6597245731323\n",
      "Epoch number 400/700\n",
      "Loss on training set: 293.7130669238128, loss on test set: 455.9817262361263\n",
      "Epoch number 400/700\n",
      "Loss on training set: 120.32831585930244, loss on test set: 290.32511402625977\n",
      "Epoch number 400/700\n",
      "Loss on training set: 10.095370741804379, loss on test set: 125.59158751190051\n",
      "Epoch number 400/700\n",
      "Loss on training set: 1029.4693684301321, loss on test set: 1171.1318731111598\n",
      "Epoch number 400/700\n",
      "Loss on training set: 162.99555374176265, loss on test set: 396.7926317154539\n",
      "Epoch number 400/700\n",
      "Loss on training set: 131.8795544486496, loss on test set: 285.54571279021445\n",
      "Epoch number 400/700\n",
      "Loss on training set: 428.40413615607076, loss on test set: 828.6685952059753\n",
      "Epoch number 400/700\n",
      "Loss on training set: 121.55889269544102, loss on test set: 208.57881101334573\n",
      "Epoch number 400/700\n",
      "Loss on training set: 83.54310081390699, loss on test set: 197.8836472141764\n",
      "Epoch number 400/700\n",
      "Loss on training set: 156.7396037803525, loss on test set: 418.4824999239498\n",
      "Epoch number 400/700\n",
      "Loss on training set: 150.9647230712344, loss on test set: 308.1599591630114\n",
      "Epoch number 400/700\n",
      "Loss on training set: 85.12579327495824, loss on test set: 197.0064447876024\n"
     ]
    }
   ],
   "source": [
    "ms_no_reg_build = {'input_shape': ms_x_train.shape, 'neurons_num': [32, 64, 32, 1], 'activations': [ReLU(), ReLU(), ReLU(), Linear()]}\n",
    "ms_no_reg_fit = [{'x_train': ms_x_train, 'y_train': ms_y_train, 'batch_size': 4, 'n_epochs': 700, 'learning_rate': 0.0003, 'x_test': ms_x_test, 'y_test': ms_y_test, 'loss': mse, 'metric': mse, 'verbose_step': 400, 'regularization_rate': 0},\n",
    "                 {'x_train': ms_x_train, 'y_train': ms_y_train, 'batch_size': 4, 'n_epochs': 700, 'learning_rate': 0.0001, 'x_test': ms_x_test, 'y_test': ms_y_test, 'loss': mse, 'metric': mse, 'verbose_step': 400, 'regularization_rate': 0},\n",
    "                 {'x_train': ms_x_train, 'y_train': ms_y_train, 'batch_size': 4, 'n_epochs': 700, 'learning_rate': 0.00005, 'x_test': ms_x_test, 'y_test': ms_y_test, 'loss': mse, 'metric': mse, 'verbose_step': 400, 'regularization_rate': 0}]\n",
    "results_train, results_test, _ = cv_network(build_args=ms_no_reg_build, fit_args=ms_no_reg_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa93da9-09fd-447b-b7f5-56f01dd5d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc['multimodal-sparse-no-reg'] = ['mse', round(np.mean(results_train)), round(np.mean(results_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b050738-ac68-4bb9-8726-afeef4ff3b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean metric train</th>\n",
       "      <th>mean metric test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multimodal-sparse-no-reg</th>\n",
       "      <td>mse</td>\n",
       "      <td>57</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  mean metric train  mean metric test\n",
       "multimodal-sparse-no-reg    mse                 57               161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0ebd1-f017-459e-9c70-2abd6db38be8",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "regularization_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfec090-1ac7-415c-824c-1f5028525fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/700\n",
      "Loss on training set: 347.2434667545519, loss on test set: 791.1746711908073\n",
      "Epoch number 400/700\n",
      "Loss on training set: 95.92488180988421, loss on test set: 245.45541107421445\n",
      "Epoch number 400/700\n",
      "Loss on training set: 21.04913718562114, loss on test set: 135.46835043401282\n",
      "Epoch number 400/700\n",
      "Loss on training set: 364.96524716743124, loss on test set: 447.0007632333909\n",
      "Epoch number 400/700\n",
      "Loss on training set: 31.80025251555884, loss on test set: 180.0717883133276\n",
      "Epoch number 400/700\n",
      "Loss on training set: 9.90972140665591, loss on test set: 153.72047560004503\n",
      "Epoch number 400/700\n",
      "Loss on training set: 323.03997737491045, loss on test set: 515.1251823609941\n",
      "Epoch number 400/700\n",
      "Loss on training set: 137.74506252344602, loss on test set: 295.7853958423769\n",
      "Epoch number 400/700\n",
      "Loss on training set: 127.55183833300521, loss on test set: 226.16863259597983\n",
      "Epoch number 400/700\n",
      "Loss on training set: 373.916924257357, loss on test set: 500.5152181150997\n",
      "Epoch number 400/700\n",
      "Loss on training set: 38.36790425292429, loss on test set: 129.71893714374053\n",
      "Epoch number 400/700\n",
      "Loss on training set: 8.31331243825468, loss on test set: 98.68808965653828\n",
      "Epoch number 400/700\n",
      "Loss on training set: 200.0904953916086, loss on test set: 458.3813743149596\n",
      "Epoch number 400/700\n",
      "Loss on training set: 65.6841237425107, loss on test set: 115.77902457702785\n",
      "Epoch number 400/700\n",
      "Loss on training set: 7.344176076762007, loss on test set: 103.77671133869008\n"
     ]
    }
   ],
   "source": [
    "ms_l2_build = {'input_shape': ms_x_train.shape, 'neurons_num': [32, 64, 32, 1], 'activations': [ReLU(), ReLU(), ReLU(), Linear()]}\n",
    "ms_l2_fit = [{'x_train': ms_x_train, 'y_train': ms_y_train, 'batch_size': 4, 'n_epochs': 700, 'learning_rate': 0.0003, 'x_test': ms_x_test, 'y_test': ms_y_test, 'loss': mse, 'metric': mse, 'verbose_step': 400, 'regularization_rate': 0.01},\n",
    "                 {'x_train': ms_x_train, 'y_train': ms_y_train, 'batch_size': 4, 'n_epochs': 700, 'learning_rate': 0.0001, 'x_test': ms_x_test, 'y_test': ms_y_test, 'loss': mse, 'metric': mse, 'verbose_step': 400, 'regularization_rate': 0.01},\n",
    "                 {'x_train': ms_x_train, 'y_train': ms_y_train, 'batch_size': 4, 'n_epochs': 700, 'learning_rate': 0.00005, 'x_test': ms_x_test, 'y_test': ms_y_test, 'loss': mse, 'metric': mse, 'verbose_step': 400, 'regularization_rate': 0.01}]\n",
    "results_train, results_test , _ = cv_network(build_args=ms_l2_build, fit_args=ms_l2_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9ed7d5-d30f-4b02-8160-fa5b72548b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc['multimodal-sparse-l2-0.01'] = ['mse', round(np.mean(results_train), 2), round(np.mean(results_test), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f8574e-8c3f-4125-9ede-97b1d3dc0347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean metric train</th>\n",
       "      <th>mean metric test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multimodal-sparse-no-reg</th>\n",
       "      <td>mse</td>\n",
       "      <td>57.00</td>\n",
       "      <td>161.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multimodal-sparse-l2-0.01</th>\n",
       "      <td>mse</td>\n",
       "      <td>33.22</td>\n",
       "      <td>137.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          metric  mean metric train  mean metric test\n",
       "multimodal-sparse-no-reg     mse              57.00            161.00\n",
       "multimodal-sparse-l2-0.01    mse              33.22            137.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5248d-e8b6-4132-87cf-783eb062f059",
   "metadata": {},
   "source": [
    "Dzięki regularyzacji średnie MSE zmalało."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275529c-2935-4593-8e52-d9455e98426f",
   "metadata": {},
   "source": [
    "# Zbiór `rings5-sparse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca87d807-c543-42eb-8f40-cbd91d985dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r5_x_train, r5_y_train = read_classification_data('../data/classification/rings5-sparse-training.csv')\n",
    "r5_x_test, r5_y_test = read_classification_data('../data/classification/rings5-sparse-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74b7dc9a-7858-4772-8535-76275b80a55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 800/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 400/400\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 800/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 400/400\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 400/800\n",
      "Loss on training set: 1.183169074040114 f_score on training set: 0.5265588808622863, loss on test set: 2.360917912181012 f_score on test set: 0.3653873143192332\n",
      "Epoch number 800/800\n",
      "Loss on training set: 0.6231349430560033 f_score on training set: 0.5811168479730204, loss on test set: 1.7938822859239498 f_score on test set: 0.4248904786890268\n",
      "Epoch number 400/400\n",
      "Loss on training set: 0.2381615132168083 f_score on training set: 0.7261048755166403, loss on test set: 1.3611452098925685 f_score on test set: 0.4634915163804198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 800/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 400/400\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 800/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 400/400\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n"
     ]
    }
   ],
   "source": [
    "r5_no_reg_build = {'input_shape': r5_x_train.shape, 'neurons_num': [40, 40, 5], 'activations': [ReLU(), ReLU(), Softmax()]}\n",
    "r5_no_reg_fit = [{'x_train': r5_x_train, 'y_train': r5_y_train, 'batch_size': 4, 'n_epochs': 800, 'learning_rate': 0.00005, 'x_test': r5_x_test, 'y_test': r5_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 400, 'regularization_rate': 0},\n",
    "                 {'x_train': r5_x_train, 'y_train': r5_y_train, 'batch_size': 4, 'n_epochs': 400, 'learning_rate': 0.00001, 'x_test': r5_x_test, 'y_test': r5_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 400, 'regularization_rate': 0}]\n",
    "                 \n",
    "results_train, results_test, _ = cv_network(build_args=r5_no_reg_build, fit_args=r5_no_reg_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56cbb384-2f27-4050-bcf3-cacf4ecdc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc['rings5-sparse-no-reg'] = ['mse', round(np.mean(results_train)), round(np.mean(results_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1472a6-f53c-405d-a401-7d472fc5cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 800/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n",
      "Epoch number 400/400\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "/home/ada/Desktop/studia/mini/sem VI/metody inteligencji obliczeniowej/MIOwAD/sieci MLP/notebooks/py_files/activation_functions.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 400/800\n",
      "Loss on training set: nan f_score on training set: 0.06666666666666668, loss on test set: nan f_score on test set: 0.00448688602765856\n"
     ]
    }
   ],
   "source": [
    "r5_l2_build = {'input_shape': r5_x_train.shape, 'neurons_num': [40, 40, 5], 'activations': [ReLU(), ReLU(), Softmax()]}\n",
    "r5_l2_fit = [{'x_train': r5_x_train, 'y_train': r5_y_train, 'batch_size': 4, 'n_epochs': 800, 'learning_rate': 0.00005, 'x_test': r5_x_test, 'y_test': r5_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 10, 'regularization_rate': 0.1},\n",
    "                 {'x_train': r5_x_train, 'y_train': r5_y_train, 'batch_size': 4, 'n_epochs': 400, 'learning_rate': 0.00001, 'x_test': r5_x_test, 'y_test': r5_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 10, 'regularization_rate': 0.1}]\n",
    "results_train, results_test, _ = cv_network(build_args=r5_no_reg_build, fit_args=r5_no_reg_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181d99f-1ee9-41cc-9bd1-8937267effcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc['rings5-sparse-l2-0.1'] = ['mse', round(np.mean(results_train)), round(np.mean(results_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac2182-364c-4a29-a1cb-9b99e2434380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b2971-e9c9-4b1f-9840-e263e6b08259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_loss(nns):\n",
    "    n = len(nns) - 1\n",
    "    sum_loss_train = np.array(nns[1].history['loss_train'])\n",
    "    sum_loss_test = np.array(nns[1].history['loss_test'])\n",
    "    for i in range(2, len(nns)):\n",
    "        sum_loss_train = np.add(sum_loss_train, np.array(nns[i].history['loss_train']))\n",
    "        sum_loss_test = np.add(sum_loss_test, np.array(nns[i].history['loss_test']))\n",
    "    return sum_loss_train / n, sum_loss_test / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788460a-b03f-4d11-931f-fd5556e7cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_loss_train = np.array(r5_no_reg_nns[1].history['loss_train'])\n",
    "sum_loss_test = np.array(r5_no_reg_nns[1].history['loss_test'])\n",
    "for i in range(2, 5):\n",
    "    sum_loss_train = np.add(sum_loss_train, np.array(r5_no_reg_nns[i].history['loss_train']))\n",
    "    sum_loss_test = np.add(sum_loss_test, np.array(r5_no_reg_nns[i].history['loss_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd70341-9461-4ab3-af23-9cfc18dc2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss_r5_no_reg = average_loss(r5_no_reg_nns)\n",
    "avg_loss_r5_l2 = average_loss(r5_l2_nns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac90d6-55ea-4cd9-a058-b6e8d79d5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(1200), avg_loss_r5_no_reg[0])\n",
    "plt.ylim(0, 5)\n",
    "plt.title('Uśredniona funkcja straty bez regularyzacji')\n",
    "plt.plot(np.arange(1200), avg_loss_r5_no_reg[1], c='red')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(270), avg_loss_r5_l2[0])\n",
    "plt.ylim(0, 5)\n",
    "plt.title('Uśredniona funkcja straty z regularyzacją L2')\n",
    "plt.plot(np.arange(270), avg_loss_r5_l2[1], c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83091e82-a588-4414-85a7-fb740375c373",
   "metadata": {},
   "source": [
    "# Zbiór `rings3-balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc584db4-2b7b-4d7e-b3db-d3918a0e433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3_x_train, r3_y_train = read_classification_data('../data/classification/rings3-balance-training.csv')\n",
    "r3_x_test, r3_y_test = read_classification_data('../data/classification/rings3-balance-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abad827-bb90-4dd2-97ac-144cae5a3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3_no_reg_build = {'input_shape': r3_x_train.shape, 'neurons_num': [40, 40, 3], 'activations': [ReLU(), ReLU(), Softmax()]}\n",
    "r3_no_reg_fit = [{'x_train': r3_x_train, 'y_train': r3_y_train, 'batch_size': 4, 'n_epochs': 800, 'learning_rate': 0.00005, 'x_test': r3_x_test, 'y_test': r3_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 400, 'regularization_rate': 0},\n",
    "                 {'x_train': r3_x_train, 'y_train': r3_y_train, 'batch_size': 4, 'n_epochs': 400, 'learning_rate': 0.00001, 'x_test': r3_x_test, 'y_test': r3_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 400, 'regularization_rate': 0}]\n",
    "                 \n",
    "results_train, results_test, _ = cv_network(build_args=r3_no_reg_build, fit_args=r3_no_reg_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6312f6b-9094-4397-b88f-f70d3d73d920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c95f9-d33c-4745-8d9e-4d47549dabc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30e616-14cd-4a35-8c17-24305bdfca13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edea6e-88a7-4fc2-8048-048ba08ed3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2893f6c-3957-4843-b5e7-c66e9b6e840f",
   "metadata": {},
   "source": [
    "# Zbiór `xor3-balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2d6b5-dcfd-4bc8-8771-4eaf41909917",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_x_train, x3_y_train = read_classification_data('../data/classification/xor3-balance-training.csv')\n",
    "x3_x_test, x3_y_test = read_classification_data('../data/classification/xor3-balance-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52874ea7-3d68-4d2f-8184-b728c7a22268",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_no_reg_build = {'input_shape': x3_x_train.shape, 'neurons_num': [40, 40, 3], 'activations': [ReLU(), ReLU(), Softmax()]}\n",
    "x3_no_reg_fit = [{'x_train': x3_x_train, 'y_train': x3_y_train, 'batch_size': 4, 'n_epochs': 800, 'learning_rate': 0.00005, 'x_test': x3_x_test, 'y_test': x3_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 400, 'regularization_rate': 0},\n",
    "                 {'x_train': x3_x_train, 'y_train': x3_y_train, 'batch_size': 4, 'n_epochs': 400, 'learning_rate': 0.00001, 'x_test': x3_x_test, 'y_test': x3_y_test, 'loss': cross_entropy, 'metric': f_score, 'verbose_step': 400, 'regularization_rate': 0}]\n",
    "                 \n",
    "results_train, results_test, _ = cv_network(build_args=x3_no_reg_build, fit_args=x3_no_reg_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d6dac-d964-4d03-9090-7f43398af089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614cedc-3597-4f81-8b29-77e7106d9049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc446f-324e-440c-b2cf-9dd58b8b300e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koh_venv",
   "language": "python",
   "name": "koh_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
